# ==============================================================================
# Avatar Chat Server - Docker Compose Configuration
# ==============================================================================
#
# Usage:
#   Production:  docker-compose up -d
#   Development: docker-compose --profile dev up
#   Logs:        docker-compose logs -f
#   Stop:        docker-compose down
#
# ==============================================================================

services:
  # ============================================================================
  # Avatar Chat Server (Production)
  # ============================================================================
  server:
    build:
      context: .
      target: production
    container_name: avatar-chat-server
    ports:
      - "${SERVER_PORT:-8080}:8080"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-realtime-preview}
      - OPENAI_VOICE=${OPENAI_VOICE:-alloy}
      - ASSISTANT_INSTRUCTIONS=${ASSISTANT_INSTRUCTIONS:-You are a helpful and friendly AI assistant.}
      - MODEL_PATH=/app/pretrained_models/wav2arkit_cpu.onnx
      - USE_GPU=${USE_GPU:-false}
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8080
      - AUTH_ENABLED=false
      - DEBUG=${DEBUG:-false}
    volumes:
      # Mount ONNX model (new model structure)
      - ./src/pretrained_models/wav2arkit_cpu.onnx:/app/pretrained_models/wav2arkit_cpu.onnx:ro
      - ./src/pretrained_models/wav2arkit_cpu.onnx.data:/app/pretrained_models/wav2arkit_cpu.onnx.data:ro
    # No GPU needed for CPU-only model
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8080/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ============================================================================
  # Avatar Chat Server (Development with hot reload)
  # ============================================================================
  server-dev:
    build:
      context: .
      target: development
    container_name: avatar-chat-server-dev
    profiles:
      - dev
    ports:
      - "${SERVER_PORT:-8080}:8080"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-realtime-preview}
      - OPENAI_VOICE=${OPENAI_VOICE:-alloy}
      - ASSISTANT_INSTRUCTIONS=${ASSISTANT_INSTRUCTIONS:-You are a helpful and friendly AI assistant.}
      - MODEL_PATH=/app/pretrained_models/wav2arkit_cpu.onnx
      - USE_GPU=${USE_GPU:-false}
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8080
      - AUTH_ENABLED=false
      - DEBUG=true
    volumes:
      # Mount source code for hot reload
      - .:/app
      # Mount ONNX model (new model structure)
      - ./src/pretrained_models/wav2arkit_cpu.onnx:/app/pretrained_models/wav2arkit_cpu.onnx:ro
      - ./src/pretrained_models/wav2arkit_cpu.onnx.data:/app/pretrained_models/wav2arkit_cpu.onnx.data:ro
    # No GPU needed for CPU-only model
